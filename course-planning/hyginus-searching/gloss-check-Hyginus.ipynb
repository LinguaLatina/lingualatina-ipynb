{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gloss passage against Hyginus, *Fabulae*\n",
    "\n",
    "> *Add link here to all the caveats...*\n",
    "\n",
    "\n",
    "### How to use this notebook\n",
    "\n",
    "1. First, run step 1 (e.g., by selecting the cell labelled **Step 1: load everything** and choosing \"Run all below\" from the \"Cell\" menu).  This will be slow, and your mileage may vary depending on how well your connection to different resources on the internet happens to be performing just then.\n",
    "2. Just below the cell labelled **Step 2: highlight this text for glossing**, fill in between quotation marks an argument to the function `highlightThis`.  E.g., to highlight vocabulary not covered in Hyginus, you could edit that cell to read\n",
    "\n",
    "\n",
    "    val highlightThis = \"Hercules Busiridem interfecit.\"\n",
    "    \n",
    "    \n",
    "\n",
    "Then run the cell (e.g., by selecting it, and choosing \"Run cells\" from the \"Cell\" menu).\n",
    "\n",
    "\n",
    "### For the tinkerers\n",
    "\n",
    "If you want to fiddle with the styling of the display, scroll down to the section labelled **CSS Styling**, and experiment as you like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: highlight this text for glossing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val highlightThis = \"Pater filiam suam Herculi dedit.\"\n",
    "val vocabUnit = 4\n",
    "highlight(highlightThis, vocabUnit)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2b (optional): find substrings occurring in Hyginus\n",
    "\n",
    "If you're not sure if a particular form of a word occurs in Hyginus, you can test that by running the cell below this one with a substring of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchForSubstring(\"potesta\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: load everything\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// set up notebook to find repository\n",
    "val personalRepo = coursierapi.MavenRepository.of(\"https://dl.bintray.com/neelsmith/maven\")\n",
    "interp.repositories() ++= Seq(personalRepo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// ivy imports\n",
    "import $ivy.`edu.holycross.shot::latincorpus:7.0.0-pr5`\n",
    "import $ivy.`edu.holycross.shot.mid::orthography:2.1.0`\n",
    "import $ivy.`edu.holycross.shot::latphone:3.0.0`\n",
    "import $ivy.`edu.holycross.shot.cite::xcite:4.3.0`\n",
    "import $ivy.`edu.holycross.shot::ohco2:10.20.4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import edu.holycross.shot.latincorpus._\n",
    "import edu.holycross.shot.latin._\n",
    "import edu.holycross.shot.mid.orthography._\n",
    "import edu.holycross.shot.cite._\n",
    "import edu.holycross.shot.ohco2._\n",
    "import scala.io.Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val hyginusUrl = \"https://raw.githubusercontent.com/LinguaLatina/analysis/master/data/hyginus/hyginus-latc.cex\"\n",
    "val hyginus = LatinCorpus.fromUrl(hyginusUrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36msearchForSubstring\u001b[39m"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def searchForSubstring(substring: String) = {\n",
    "  val matches = hyginus.tokens.filter(_.text.contains(substring)).map(_.text)\n",
    "  val bullets = matches.distinct.sorted.map(str => s\"<li>${str}</li>\")\n",
    "  val matchList = \"<ul>\" + bullets.mkString(\"\\n\") + \"</ul>\"\n",
    "  val heading = s\"<h2>Matches for <em>${substring}</em> in Hyginus</h2>\"\n",
    "  val para = s\"<p>${bullets.size} matches:</p>\"\n",
    "  \n",
    "  Html(heading + para + matchList)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mlat23orthogaphy\u001b[39m: \u001b[32mMidOrthography\u001b[39m = Latin alphabet with 23 alphabetic characters.\n",
       "\u001b[36mfstUrl\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"https://raw.githubusercontent.com/LinguaLatina/analysis/master/data/hyginus/hyginus-fst.txt\"\u001b[39m\n",
       "\u001b[36mfstLines\u001b[39m: \u001b[32mVector\u001b[39m[\u001b[32mString\u001b[39m] = \u001b[33mVector\u001b[39m(\n",
       "  \u001b[32m\"> a\"\u001b[39m,\n",
       "  \u001b[32m\"<u>latcommon.indecln4</u><u>ls.n4</u>a<indecl><indeclprep><div><indeclprep><indecl><u>indeclinfl.1</u>\"\u001b[39m,\n",
       "  \u001b[32m\"> ab\"\u001b[39m,\n",
       "  \u001b[32m\"<u>latcommon.indecln5</u><u>ls.n4</u>ab<indecl><indeclprep><div><indeclprep><indecl><u>indeclinfl.1</u>\"\u001b[39m,\n",
       "  \u001b[32m\"> abanti\"\u001b[39m,\n",
       "  \u001b[32m\"no result for abanti\"\u001b[39m,\n",
       "  \u001b[32m\"> abantis\"\u001b[39m,\n",
       "  \u001b[32m\"no result for abantis\"\u001b[39m,\n",
       "  \u001b[32m\"> abas\"\u001b[39m,\n",
       "  \u001b[32m\"no result for abas\"\u001b[39m,\n",
       "  \u001b[32m\"> abdero\"\u001b[39m,\n",
       "  \u001b[32m\"no result for abdero\"\u001b[39m,\n",
       "  \u001b[32m\"> abdidit\"\u001b[39m,\n",
       "  \u001b[32m\"no result for abdidit\"\u001b[39m,\n",
       "  \u001b[32m\"> abducere\"\u001b[39m,\n",
       "  \u001b[32m\"<u>latcommon.compoundn55_0</u><u>ls.n55</u><#>abduc<verb><c3pres><div><c3pres><verb>ere<2nd><sg><pres><indic><pass><u>latcommon.ere3_c3prespres8b</u>\"\u001b[39m,\n",
       "  \u001b[32m\"<u>latcommon.compoundn55_0</u><u>ls.n55</u><#>abduc<verb><c3pres><div><c3pres><verb>ere<2nd><sg><fut><indic><pass><u>latcommon.ere3_c3presfut8b</u>\"\u001b[39m,\n",
       "  \u001b[32m\"<u>latcommon.compoundn55_0</u><u>ls.n55</u><#>abduc<verb><c3pres><div><c3pres><infin>ere<pres><act><u>latcommoninfl.ere3_inf4</u>\"\u001b[39m,\n",
       "  \u001b[32m\"> abducerent\"\u001b[39m,\n",
       "  \u001b[32m\"<u>latcommon.compoundn55_0</u><u>ls.n55</u><#>abduc<verb><c3pres><div><c3pres><verb>erent<3rd><pl><impft><subj><act><u>latcommon.ere3_c3presimpft18</u>\"\u001b[39m,\n",
       "  \u001b[32m\"> abduxit\"\u001b[39m,\n",
       "  \u001b[32m\"<u>latcommon.compoundn55_0</u><u>ls.n55</u><#>abdux<verb><pftact><div><pftact><verb>it<3rd><sg><pft><indic><act><u>latcommon.pftact_pft3</u>\"\u001b[39m,\n",
       "  \u001b[32m\"> abegit\"\u001b[39m,\n",
       "  \u001b[32m\"<u>latcommon.compoundn87_3</u><u>ls.n87</u><#>abeg<verb><pftact><div><pftact><verb>it<3rd><sg><pft><indic><act><u>latcommon.pftact_pft3</u>\"\u001b[39m,\n",
       "  \u001b[32m\"> aberrantes\"\u001b[39m,\n",
       "  \u001b[32m\"no result for aberrantes\"\u001b[39m,\n",
       "  \u001b[32m\"> aberrauit\"\u001b[39m,\n",
       "  \u001b[32m\"no result for aberrauit\"\u001b[39m,\n",
       "  \u001b[32m\"> abesset\"\u001b[39m,\n",
       "  \u001b[32m\"<u>latcommon.irrverbn25445</u><u>ls.n254</u><#>abesset<3rd><sg><impft><subj><\u001b[39m...\n",
       "\u001b[36mvocabFiles\u001b[39m: \u001b[32mMap\u001b[39m[\u001b[32mInt\u001b[39m, \u001b[32mString\u001b[39m] = \u001b[33mMap\u001b[39m(\n",
       "  \u001b[32m1\u001b[39m -> \u001b[32m\"https://raw.githubusercontent.com/LinguaLatina/textbook/master/vocablists/01-nouns-adjs-pron.cex\"\u001b[39m,\n",
       "  \u001b[32m2\u001b[39m -> \u001b[32m\"https://raw.githubusercontent.com/LinguaLatina/textbook/master/vocablists/02-verbs.cex\"\u001b[39m,\n",
       "  \u001b[32m3\u001b[39m -> \u001b[32m\"https://raw.githubusercontent.com/LinguaLatina/textbook/master/vocablists/03-place-and-time.cex\"\u001b[39m,\n",
       "  \u001b[32m4\u001b[39m -> \u001b[32m\"https://raw.githubusercontent.com/LinguaLatina/textbook/master/vocablists/04-verbal-nouns-and-adjectives.cex\"\u001b[39m\n",
       ")\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mvocabForUnit\u001b[39m"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Settings:\n",
    "val lat23orthogaphy: MidOrthography = Latin23Alphabet\n",
    "val fstUrl = \"https://raw.githubusercontent.com/LinguaLatina/analysis/master/data/hyginus/hyginus-fst.txt\"\n",
    "val fstLines = Source.fromURL(fstUrl).getLines.toVector\n",
    "\n",
    "\n",
    "val vocabFiles : Map[Int, String] = Map(\n",
    "  1 -> \"https://raw.githubusercontent.com/LinguaLatina/textbook/master/vocablists/01-nouns-adjs-pron.cex\",\n",
    "  2 -> \"https://raw.githubusercontent.com/LinguaLatina/textbook/master/vocablists/02-verbs.cex\",\n",
    "  3 -> \"https://raw.githubusercontent.com/LinguaLatina/textbook/master/vocablists/03-place-and-time.cex\",\n",
    "  4 -> \"https://raw.githubusercontent.com/LinguaLatina/textbook/master/vocablists/04-verbal-nouns-and-adjectives.cex\"\n",
    ")\n",
    "def vocabForUnit(vocabUnit: Int): Vector[String] = {\n",
    "  val vocab = for (i <- 1 to vocabUnit) yield {\n",
    "    val lines = Source.fromURL(vocabFiles(i))\n",
    "    val lexemeIds = lines.getLines.toVector.tail.filter(_.nonEmpty).map( ln => {\n",
    "      val columns = ln.split(\"#\")\n",
    "      val idParts = columns.head.split(\":\")\n",
    "      idParts.head\n",
    "    })\n",
    "    lexemeIds\n",
    "  }\n",
    "  vocab.toVector.flatten\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSS styling\n",
    "\n",
    "If you want to define your own visual styling for highlighting ambiguous tokens, unanalyzed tokens, and tokens from the chapter vocabulary, you can edit the following cell, then rerun both of the cells below this (e.g., select this cell and choose \"Run all below\" from the \"Cell\" menu). \n",
    "\n",
    "Your new styling will then be used the next time you run **Step 2: highlight this text for glossing**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mambiguousCss\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"text-decoration-line: underline; text-decoration-style: wavy; text-decoration-color: silver;\"\u001b[39m\n",
       "\u001b[36munanalyzedCss\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"text-decoration-line: underline; text-decoration-style: double; text-decoration-color:rgb(159, 69, 17);\"\u001b[39m\n",
       "\u001b[36mvocabCss\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"color:rgb(24, 23, 162);\"\u001b[39m"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// CSS definitions\n",
    "\n",
    "// CSS styling for tokens with multiple analyses\n",
    "val ambiguousCss = \"text-decoration-line: underline; text-decoration-style: wavy; text-decoration-color: silver;\"\n",
    "// CSS styling for tokens with no analyses\n",
    "val unanalyzedCss = \"text-decoration-line: underline; text-decoration-style: double; text-decoration-color:rgb(159, 69, 17);\"\n",
    "// CSS styling for tokens in vocabulary list for this unit\n",
    "val vocabCss = \"color:rgb(24, 23, 162);\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mbullets\u001b[39m: \u001b[32mVector\u001b[39m[\u001b[32mString\u001b[39m] = \u001b[33mVector\u001b[39m(\n",
       "  \u001b[32m\"<li style=\\\"color:rgb(24, 23, 162);\\\">In vocab list</li>\"\u001b[39m,\n",
       "  \u001b[32m\"<li  style=\\\"text-decoration-line: underline; text-decoration-style: double; text-decoration-color:rgb(159, 69, 17);\\\">Not analyzed</li>\"\u001b[39m,\n",
       "  \u001b[32m\"<li  style=\\\"text-decoration-line: underline; text-decoration-style: wavy; text-decoration-color: silver;\\\">Mutiple analyses</li>\"\u001b[39m\n",
       ")\n",
       "\u001b[36mstyleKey\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"\"\"<h3>Key</h3><ul><li style=\"color:rgb(24, 23, 162);\">In vocab list</li>\n",
       "<li  style=\"text-decoration-line: underline; text-decoration-style: double; text-decoration-color:rgb(159, 69, 17);\">Not analyzed</li>\n",
       "<li  style=\"text-decoration-line: underline; text-decoration-style: wavy; text-decoration-color: silver;\">Mutiple analyses</li></ul>\"\"\"\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mhighlight\u001b[39m"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// The action:\n",
    " val bullets = Vector(\n",
    "   \"<li style=\\\"\" + vocabCss + \"\\\">In vocab list</li>\",\n",
    "   \"<li  style=\\\"\" + unanalyzedCss + \"\\\">Not analyzed</li>\",\n",
    "   \"<li  style=\\\"\" + ambiguousCss + \"\\\">Mutiple analyses</li>\"\n",
    "   )\n",
    "val styleKey = \"<h3>Key</h3><ul>\" + bullets.mkString(\"\\n\") + \"</ul>\"\n",
    "       \n",
    "\n",
    "\n",
    "def highlight(txt: String, vocabUnit: Int) = {\n",
    "    if (! vocabFiles.keySet.contains(vocabUnit)) {\n",
    "      Html(\"Sorry, but currently only have vocabulary lists for these units:  \" + vocabFiles.keySet.toVector.sorted.mkString(\", \"))\n",
    "\n",
    "    } else {\n",
    "      try {\n",
    "        val vocab = vocabForUnit(vocabUnit)\n",
    "        val highlighter = LexemesHighlighter(vocab, vocabCss)\n",
    "        // make an ohco2 Corpus in order to tokenize text.\n",
    "        val fakeUrn = CtsUrn(\"urn:cts:fake:exercise.v1:1\")\n",
    "        val citable = CitableNode(fakeUrn, txt)\n",
    "        val exercise = Corpus(Vector(citable))\n",
    "        val latc = LatinCorpus.fromFstLines(exercise,lat23orthogaphy, fstLines, strict=false)\n",
    "\n",
    "        val formatted = StringFormatter.tokensLexemeStyled(\n",
    "          latc.tokens,\n",
    "          highlighter,\n",
    "          vocab,\n",
    "          formAmbiguityStyle = ambiguousCss, \n",
    "          lexicalAmbiguityStyle = \"\", \n",
    "          unanalyzedStyle = unanalyzedCss\n",
    "        )        \n",
    "        \n",
    "        val header = s\"<h2>Highlight with vocabulary from unit ${vocabUnit}</h2>\"\n",
    "        val nb = s\"<p>Through unit ${vocabUnit}, vocabulary includes <strong>${vocab.size}</strong> vocabulary items.\"\n",
    "        val prefatoryPara = \"<p>Text to highlight: <em>\" + txt + \"</em></p>\"\n",
    "        \n",
    "        Html(header + nb + prefatoryPara +\n",
    "             s\"<hr/><h2>Highlighted view</h2>${styleKey}<p>${formatted}\")\n",
    "        \n",
    "        } catch {\n",
    "         case nope: java.util.NoSuchElementException => {\n",
    "         Html(\"<p><em>\" + txt + \"</em> : something went wrong. :-(</p>\")\n",
    "         }\n",
    "       }\n",
    "      }\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala (2.12)",
   "language": "scala",
   "name": "scala212"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.10"
  },
  "nteract": {
   "version": "0.24.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
