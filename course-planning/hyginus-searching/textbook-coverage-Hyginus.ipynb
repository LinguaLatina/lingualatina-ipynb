{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Textbook coverage of vocabulary in Hyginus, *Fabulae*\n",
    "\n",
    "Read vocabulary lists for L3 textbook, compute percentage of total tokens in Hyginus (excluding proper names) covered by accumulated vocabulary for each unit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: display coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing coverage of unit 1... 29.3%\n",
      "Computing coverage of unit 2... 40.8%\n",
      "Computing coverage of unit 3... 58.2%\n",
      "Computing coverage of unit 4... 62.9%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h2>L3 vocabulary lists: coverage of Hyginus</h2><table><tr><th>Unit</th><th>Pct. Hyginus</th><th>Vocabulary items</th></tr><tr><td>Vocabulary through unit 1 vocabulary</td><td>covers <strong>29.3%</strong> of tokens in Hyginus</td><td><strong>35</strong> vocabulary items</td></tr>\n",
       "<tr><td>Vocabulary through unit 2 vocabulary</td><td>covers <strong>40.8%</strong> of tokens in Hyginus</td><td><strong>69</strong> vocabulary items</td></tr>\n",
       "<tr><td>Vocabulary through unit 3 vocabulary</td><td>covers <strong>58.2%</strong> of tokens in Hyginus</td><td><strong>109</strong> vocabulary items</td></tr>\n",
       "<tr><td>Vocabulary through unit 4 vocabulary</td><td>covers <strong>62.9%</strong> of tokens in Hyginus</td><td><strong>144</strong> vocabulary items</td></tr></table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "survey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: load everything\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// set up notebook to find repository\n",
    "val personalRepo = coursierapi.MavenRepository.of(\"https://dl.bintray.com/neelsmith/maven\")\n",
    "interp.repositories() ++= Seq(personalRepo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// ivy imports\n",
    "import $ivy.`edu.holycross.shot::latincorpus:7.0.0-pr5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import edu.holycross.shot.latincorpus._\n",
    "import scala.io.Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val hyginusUrl = \"https://raw.githubusercontent.com/LinguaLatina/analysis/master/data/hyginus/hyginus-latc.cex\"\n",
    "val hyginus = LatinCorpus.fromUrl(hyginusUrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val tokens = hyginus.tokens.filter(_.text.head.isLower)\n",
    "\n",
    "val total = tokens.size\n",
    "val totalAnalyzed = tokens.filter(_.analyses.nonEmpty).size\n",
    "\n",
    "val analysisCoverage = (totalAnalyzed * 1.0 / total) * 100\n",
    "val analysisPct = BigDecimal(analysisCoverage).setScale(1, BigDecimal.RoundingMode.HALF_UP).toDouble\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val vocabFiles : Map[Int, String] = Map(\n",
    "  1 -> \"https://raw.githubusercontent.com/LinguaLatina/textbook/master/vocablists/01-nouns-adjs-pron.cex\",\n",
    "  2 -> \"https://raw.githubusercontent.com/LinguaLatina/textbook/master/vocablists/02-verbs.cex\",\n",
    "  3 -> \"https://raw.githubusercontent.com/LinguaLatina/textbook/master/vocablists/03-place-and-time.cex\",\n",
    "  4 -> \"https://raw.githubusercontent.com/LinguaLatina/textbook/master/vocablists/04-verbal-nouns-and-adjectives.cex\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mtempOmit\u001b[39m: \u001b[32mList\u001b[39m[\u001b[32mString\u001b[39m] = \u001b[33mList\u001b[39m(\n",
       "  \u001b[32m\"ls.n49983\"\u001b[39m,\n",
       "  \u001b[32m\"ls.n40071\"\u001b[39m,\n",
       "  \u001b[32m\"ls.n25107\"\u001b[39m,\n",
       "  \u001b[32m\"ls.n28700\"\u001b[39m,\n",
       "  \u001b[32m\"ls.38383\"\u001b[39m,\n",
       "  \u001b[32m\"ls.n40913\"\u001b[39m\n",
       ")\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mvocabForUnit\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36munitCoverage\u001b[39m"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Omit these IDs until parser recompiled\n",
    "val tempOmit = List(\n",
    "  \"ls.n49983\", \n",
    "  \"ls.n40071\",\n",
    "  \"ls.n25107\", \n",
    "  \"ls.n28700\",\n",
    "  \"ls.38383\", \n",
    "  \"ls.n40913\"\n",
    ")\n",
    "\n",
    "def vocabForUnit(vocabUnit: Int): Vector[String] = {\n",
    "  val vocab = for (i <- 1 to vocabUnit) yield {\n",
    "    val lines = Source.fromURL(vocabFiles(i))\n",
    "    val lexemeIds = lines.getLines.toVector.tail.filter(_.nonEmpty).map( ln => {\n",
    "      val columns = ln.split(\"#\")\n",
    "      val idParts = columns.head.split(\":\")\n",
    "      idParts.head\n",
    "    })\n",
    "    lexemeIds\n",
    "  }\n",
    "  vocab.toVector.flatten.filterNot(v => tempOmit.contains(v))\n",
    "}\n",
    "\n",
    "def unitCoverage(vocabUnit: Int) = {\n",
    "  val counts = vocabForUnit(vocabUnit).map(lex => hyginus.passagesForLexeme(lex).size)\n",
    "  val unitCoverage = (counts.sum * 1.0 / total) * 100\n",
    "  val unitPct = BigDecimal(unitCoverage).setScale(1, BigDecimal.RoundingMode.HALF_UP).toDouble\n",
    "  (unitPct, counts.size)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36msurvey\u001b[39m"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def survey = {\n",
    "  val rows = for (i <- 1 to 4) yield {\n",
    "    print(\"Computing coverage of unit \" + i + \"... \")\n",
    "    val (pct, vocabSize) = unitCoverage(i)\n",
    "    println(pct + \"%\")\n",
    "    \"<tr>\"+\n",
    "    s\"<td>Vocabulary through unit ${i} vocabulary</td>\" +\n",
    "    s\"<td>covers <strong>${pct}%</strong> of tokens in Hyginus</td>\" +\n",
    "    s\"<td><strong>${vocabSize}</strong> vocabulary items</td>\" +\n",
    "    \"</tr>\"\n",
    "  }\n",
    "  \n",
    "  val header = \"<h2>L3 vocabulary lists: coverage of Hyginus</h2>\"\n",
    "  val tableHeader = \"<tr><th>Unit</th><th>Pct. Hyginus</th><th>Vocabulary items</th></tr>\"\n",
    "  Html(header + \"<table>\"  + tableHeader + rows.mkString(\"\\n\") + \"</table>\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala (2.12)",
   "language": "scala",
   "name": "scala212"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.10"
  },
  "nteract": {
   "version": "0.24.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
